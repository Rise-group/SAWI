{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights\n",
    "\n",
    "This notebook aquires the weights for the principal components analysis (PCA) and analytic hierarchy process (AHP) methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import utils.analysis as an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the names of the territories\n",
    "l_names = pd.read_csv('../data/input/table/mpios_names.txt',header=None)\n",
    "l_names = list(l_names[0])\n",
    "\n",
    "# Types of codes\n",
    "codes_names_list = ['health','sport','education','financial','cultural','parks']\n",
    "\n",
    "# Import the population data\n",
    "DANE_data = pd.read_csv('../data/input/table/DANE_2018_personas_manz.txt',low_memory=False)\n",
    "pop = DANE_data[['MANZ_CCNCT','poblacion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blocks = []\n",
    "for m in l_names:\n",
    "    # Import blocks\n",
    "    blocks = gpd.read_file(f'../data/output/shape/blocks/{m}_blocks.shp')\n",
    "    blocks = blocks[['MANZ_CCNCT','geometry']]\n",
    "    blocks['territory'] = m\n",
    "    \n",
    "    # Combine the population and the blocks\n",
    "    blocks = blocks.set_index('MANZ_CCNCT').join(pop.set_index('MANZ_CCNCT'))\n",
    "    blocks = blocks.reset_index()\n",
    "    blocks = blocks.rename(columns={'poblacion':'p_(h)'})\n",
    "    # Change the NaN values for 0.0\n",
    "    blocks = blocks.fillna(0.0)\n",
    "\n",
    "    # Create a list with the accessibility type names: health, sport, etc.\n",
    "    A_i_names = []\n",
    "    # Create a list with the normalized accessibility type names\n",
    "    N_i_names = []\n",
    "    # Create a loop to agregate each accessibility measure to the blocks\n",
    "    for c in codes_names_list:\n",
    "        # Import the accessibility DataFrame\n",
    "        acc_i_df = pd.read_csv(f'../data/output/table/accessibility_dfs/contour/accessibility_i_contour_15min_{m}_{c}.txt')\n",
    "        # Filter the accessibility DataFrame\n",
    "        acc_i_df = acc_i_df[['MANZ_CCNCT','Acc_i']]\n",
    "        A_i_names.append(f'A_i_{c[:3]}')\n",
    "        N_i_names.append(f'N_i_{c[:3]}')\n",
    "        # Rename the accessibility column with the respective type\n",
    "        acc_i_df = acc_i_df.rename(columns={'Acc_i':f'A_i_{c[:3]}'})\n",
    "        blocks = blocks.merge(acc_i_df,on='MANZ_CCNCT',how='left')\n",
    "        blocks = blocks.fillna(0.0)\n",
    "    # Eliminate blocks with 0 population\n",
    "    blocks_norm = blocks.copy()\n",
    "    blocks_norm = blocks_norm.drop(blocks_norm[blocks_norm['p_(h)']==0].index).reset_index(drop=True)\n",
    "\n",
    "    for i in range(len(A_i_names)):\n",
    "        if blocks_norm[A_i_names[i]].max() == blocks_norm[A_i_names[i]].min():\n",
    "            blocks_norm[N_i_names[i]] = blocks_norm[A_i_names[i]]\n",
    "        else:\n",
    "            blocks_norm[N_i_names[i]] = (blocks_norm[A_i_names[i]]-blocks_norm[A_i_names[i]].min())/(blocks_norm[A_i_names[i]].max()-blocks_norm[A_i_names[i]].min())\n",
    "    blocks_norm = blocks_norm.fillna(0.0)\n",
    "    blocks_norm = blocks_norm.set_index('MANZ_CCNCT')\n",
    "\n",
    "    all_blocks.append(blocks_norm)\n",
    "    \n",
    "all_blocks = pd.concat(all_blocks)\n",
    "blocks_norm = all_blocks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = blocks_norm.copy()\n",
    "pca_df = pca_df[N_i_names]\n",
    "n_PC, exp_var, weights = an.weights_PCA(pca_df,0.6)\n",
    "weights.to_csv('../data/output/table/weights/PCA_weights.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency of each criteria:\n",
      "soc CR 0.0148\n",
      "env CR 0.025\n",
      "eco CR 0.0108\n"
     ]
    }
   ],
   "source": [
    "## Aggregating Individual Judgements AIJ\n",
    "\n",
    "r = 13\n",
    "total_surveys = list(range(r))\n",
    "# s = total_surveys[0]\n",
    "# print(total_surveys)\n",
    "# total_surveys = [1]\n",
    "\n",
    "# List to store the matrices\n",
    "# matrices_criteria = []\n",
    "matrices_soc = []\n",
    "matrices_env = []\n",
    "matrices_eco = []\n",
    "\n",
    "for s in total_surveys:\n",
    "    \n",
    "    data = pd.read_csv(f'C:/Users/Sergio/OneDrive - Universidad EAFIT/Accesibilidad/data/input/table/AHP_responses/Encuesta_AHP_{s}.csv',sep=';')\n",
    "    data = data.fillna(0)\n",
    "    # Eliminate rows with no value in the aim cell\n",
    "    data = data[data[data.columns[-1]]!=0]\n",
    "    data = data.rename(columns={'Encuesta para la Evaluación de Servicios Básicos Mediante la Metodología AHP':'one','Unnamed: 10':'two','Unnamed: 12':'value'})\n",
    "    data = data[['one','two','value']]\n",
    "    # Without the criterias\n",
    "    data_soc = data.iloc[:15].reset_index(drop=True)\n",
    "    data_env = data.iloc[15:30].reset_index(drop=True)\n",
    "    data_eco = data.iloc[30:].reset_index(drop=True)\n",
    "\n",
    "    # AHPs\n",
    "    AHP_soc = an.extract_survey_information(data_soc)\n",
    "    AHP_env = an.extract_survey_information(data_env)\n",
    "    AHP_eco = an.extract_survey_information(data_eco)\n",
    "    \n",
    "    # Add the the lists\n",
    "    matrices_soc.append(AHP_soc)\n",
    "    matrices_env.append(AHP_env)\n",
    "    matrices_eco.append(AHP_eco)\n",
    "    \n",
    "# Average matrices\n",
    "# https://www.spicelogic.com/docs/ahpsoftware/intro/ahp-group-decision-making-395\n",
    "# Forman 1998\n",
    "avg_soc = an.calculate_average(matrices_soc, method='geometric')\n",
    "avg_env = an.calculate_average(matrices_env, method='geometric')\n",
    "avg_eco = an.calculate_average(matrices_eco, method='geometric')\n",
    "\n",
    "# Weights españa\n",
    "CR_soc,pre_weights_soc = an.calculate_consistency_and_pre_weights(avg_soc)\n",
    "CR_env,pre_weights_env = an.calculate_consistency_and_pre_weights(avg_env)\n",
    "CR_eco,pre_weights_eco = an.calculate_consistency_and_pre_weights(avg_eco)\n",
    "\n",
    "print('Consistency of each criteria:')\n",
    "print('soc CR',np.round(CR_soc,4))\n",
    "print('env CR',np.round(CR_env,4))\n",
    "print('eco CR',np.round(CR_eco,4))\n",
    "\n",
    "pre_weights_matrix = pd.DataFrame()\n",
    "pre_weights_matrix['soc'] = pre_weights_soc\n",
    "pre_weights_matrix['env'] = pre_weights_env\n",
    "pre_weights_matrix['eco'] = pre_weights_eco\n",
    "\n",
    "criteria_matrix = pd.DataFrame({'soc':1/3,'env':1/3,'eco':1/3},index=['w']).T\n",
    "criteria_matrix\n",
    "\n",
    "weights = pre_weights_matrix@criteria_matrix\n",
    "N_i_names = ['hea', 'spo', 'edu', 'fin', 'cul', 'par']\n",
    "weights = weights.reindex(N_i_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.to_csv('../data/output/table/weights/AHP_weights.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox_GIZ_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
